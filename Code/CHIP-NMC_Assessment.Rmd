---
title: "CHIP-NMC: Corn Hybrid and Inbred Prediction of Nixtamalization Moisture Content"
author: "Michael Burns"
date: '2024-11-13'
output: html_document
---

It was decided to split the hybrid nixtamalziation moisture content paper into two separate papers. This paper will focus on the development of the hybrid nixtamalization model. The second paper will focus on the biological relationships this model helps us investigate.

The moisture content prediction model from Burns et al. 2021 does not very accurately predict the moisture content of hybrid seed.  This could be for a number of reasons from lack of dynamic range in hybrids to lack of sample size, to a difference in the morphology and compositional distribution of hybrids compared to inbreds that is not captured by the NIR scanning of ground samples. My primary suspicion is the last option, but to test the others I am going to include more preprocessing techniques from the prospectr package to try to improve the model to a more general and accurate state.

# Libraries

The first step is to load the libraries that will be needed
```{r libraries, message = F, warning = F}
library(multcompView)
library(caret)
library(prospectr)
library(magrittr)
library(lme4)
library(slider)
library(magrittr)
library(tidyverse)
library(ggpubr)
```

# Loading the Data
```{r load data, message = F, warning = F}
inbred_train_data = read_csv('~/Desktop/Grad_School/Research/CHIP-NMC/Data/Burns_et_al_2021_Inbred_Training_Set.csv') %>%
  select(1,2,26:167)

inbred_val_data = read_csv('~/Desktop/Grad_School/Research/CHIP-NMC/Data/Burns_et_al_2021_Inbred_Validation_Set.csv') %>%
  rename(Sample_ID = SampleID)

hybrid_scans = read_csv('~/Desktop/Grad_School/Research/CHIP-NMC/Data/Scans/Hybrid_Maize_NIR_Spectra_Coded.csv')

hybrid_data = read_csv('~/Desktop/Grad_School/Research/CHIP-NMC/Data/Hybrid_Training_Data_305_Coded.csv')

hybrid_val_data = read_csv('~/Desktop/Grad_School/Research/CHIP-NMC/Data/Final_Validation_Samples_Coded.csv')

sum(hybrid_val_data$Genotype %in% hybrid_data$Genotype)

hybrid_genos_xref = read_csv('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Data/XRefs/Hybrid_Genotypes_XRef_Coded.csv') %>%
  unique()

# hybrid_data %>%
#   write_csv('~/Desktop/Grad_School/Research/CHIP-NMC/Data/Hybrid_Training_Data.csv')
```

# Evaluating the Inbred Model on Hybrids
## Training and Validating the Inbred Model
To start, we will train the SVML model from Burns et al. 2021 and verify it is the same by testing its performance on the inbred validation dataset.

Start by performing an absolute value normalization of the training and validation data
```{r normalizing training data, message = F, warning = F}
training_norm <- inbred_train_data %>%
  pivot_longer(cols = -c(Sample_ID, Genotype, Moisture_Uptake), names_to = "Waveband", values_to = "Absorbance") %>%
  group_by(Sample_ID) %>%
  mutate(sum_lxl_abs = sum(abs(Absorbance)),
         Norm_Abs = Absorbance / sum_lxl_abs) %>%
  select(-c(Absorbance, sum_lxl_abs)) %>%
  ungroup() %>%
  pivot_wider(id_cols = c(Sample_ID, Genotype, Moisture_Uptake), 
              values_from = Norm_Abs, 
              names_from = Waveband)

validation_norm <- inbred_val_data %>%
  filter(Sample_ID != 'YC16:1029') %>%
  select(-c(3:8)) %>%
  pivot_longer(cols = -c(Sample_ID, Genotype), names_to = "Waveband", values_to = "Absorbance") %>%
  group_by(Sample_ID) %>%
  mutate(sum_lxl_abs = sum(abs(Absorbance)),
         Norm_Abs = Absorbance / sum_lxl_abs) %>%
  select(-c(Absorbance, sum_lxl_abs)) %>%
  ungroup() %>%
  pivot_wider(id_cols = c(Sample_ID, Genotype), 
              values_from = Norm_Abs, 
              names_from = Waveband)
```

```{r training and validating inbred model, message = F, warning = F}
svml_model = train(Moisture_Uptake ~ ., 
                        data = training_norm %>%
                          select_if(is.numeric), 
                        method = "svmLinear", 
                        metric = "Rsquared", 
                        tuneGrid = expand.grid(C = 71.407),
                        trControl = trainControl(method = "cv",
                                                 index = groupKFold(training_norm$Genotype, k = 10), 
                                                 savePredictions = T,
                                                 allowParallel = T
                                                 )
                        )

val_predictions = predict(svml_model, validation_norm)

val_interpolate_index = val_predictions > min(inbred_train_data$Moisture_Uptake) & val_predictions < max(inbred_train_data$Moisture_Uptake)

cor_inbred_val = inbred_val_data %>%
  filter(Sample_ID != 'YC16:1029') %>%
  select(Moisture_Uptake) %>%
  mutate(Predictions = val_predictions,
         Keep = val_interpolate_index) %>%
  filter(Keep == T) %$%
  cor(Moisture_Uptake, Predictions, method = 'spearman')

actual_pred_rel_model = lm(inbred_val_data$Moisture_Uptake[-1][val_interpolate_index] ~ val_predictions[val_interpolate_index])
inbred_pred_interval = as_tibble(predict(actual_pred_rel_model, newdata = tibble(val_predictions[val_interpolate_index]), interval = 'predict'))

inbred_val_data %>%
  filter(Sample_ID != 'YC16:1029') %>%
  mutate(Predictions = val_predictions,
         Keep = val_interpolate_index) %>%
  filter(Keep == T) %>%
  bind_cols(inbred_pred_interval) %>%
  select(Moisture_Uptake, Predictions, lwr, upr) %>%
  ggplot(aes(x = Predictions, y = Moisture_Uptake))+
  geom_ribbon(aes(ymin = lwr, ymax = upr), fill = 'gray80')+
  geom_abline(slope = 1, linetype = 'dashed', size = 1, color = 'gray40')+
  geom_point()+
  geom_smooth(se = F, method = 'lm', color = 'black')+
  labs(x = 'Actual Moisture Content',
       y = 'Predicted Moisture Content',
       title = 'Validation of Inbred Model Performance')+
  annotate('text', label = paste0('Spearman R: ', round(cor_inbred_val, 3)), x = 0.48, y = 0.4)+
  theme_classic()
```

This looks right. The correlation is a little lower than it was in Burns et al. 2021, but I know I am not filtering quite right (I have 38 points as opposed to 37).

Lets try this model on the hybrid scan data that I have.

## Testing the inbred model on hybrid data
```{r testing inbred model on hybrids, message = F, warning = F}
# Normalize new data
hybrid_norm <- hybrid_data %>%
  filter(str_detect(Sample_ID, '^YCH')) %>%
  pivot_longer(cols = -c(Sample_ID, Genotype, Moisture.Avg, Location, Source, Experiment), names_to = "Waveband", values_to = "Absorbance") %>%
  group_by(Sample_ID) %>%
  mutate(sum_lxl_abs = sum(abs(Absorbance)),
         Norm_Abs = Absorbance / sum_lxl_abs) %>%
  select(-c(Absorbance, sum_lxl_abs)) %>%
  ungroup() %>%
  pivot_wider(id_cols = c(Sample_ID, Genotype, Moisture.Avg, Location, Source, Experiment), 
              values_from = Norm_Abs, 
              names_from = Waveband)

# Save the correlation value
cor_inbred_hybrid = hybrid_norm %>%
  select(Moisture.Avg) %>%
  mutate(Predictions = predict(svml_model, hybrid_norm)) %$%
  cor.test(Moisture.Avg, Predictions, method = 'spearman')

# Model the linear relationship between predicted and actual moisture content
actual_pred_rel_model = lm(hybrid_norm$Moisture.Avg ~ predict(svml_model, hybrid_norm))

# Extract the upper and lower confidence prediction intervals
hybrid_pred_interval = as_tibble(predict(actual_pred_rel_model, newdata = tibble(predict(svml_model, hybrid_norm)), interval = 'predict'))

# Plot the correlation between predicted and actual moisture content
hybrid_inbred_preds = hybrid_norm %>%
  bind_cols(hybrid_pred_interval) %>% # combine hybrid data with prediction intervals
  left_join(hybrid_data %>% select(Sample_ID, Experiment)) %>%
  select(Moisture.Avg, lwr, upr, Experiment) %>% # Select the values needed for plotting
  mutate(Predictions = predict(svml_model, hybrid_norm))

paste('Minimum Prediction:', min(hybrid_inbred_preds$Predictions))
paste('Maximum Prediction:', max(hybrid_inbred_preds$Predictions))

inbred_on_hybrid = hybrid_inbred_preds %>% # Add the moisture content predictions
  ggplot(aes(x = Predictions, y = Moisture.Avg))+
  geom_abline(slope = 1, linetype = 'dashed', size = 1, color = 'gray40')+ # Plot a 1:1 line for comparison
  geom_point()+
  geom_smooth(se = F, method = 'lm')+ # Plot the trendline without the standard error
  geom_smooth(se = F, method = 'lm', color = 'black')+
  xlim(min(c(hybrid_inbred_preds$Predictions,
             hybrid_inbred_preds$Moisture.Avg)),
       max(c(hybrid_inbred_preds$Predictions,
             hybrid_inbred_preds$Moisture.Avg)))+
  ylim(min(c(hybrid_inbred_preds$Predictions,
             hybrid_inbred_preds$Moisture.Avg)),
       max(c(hybrid_inbred_preds$Predictions,
             hybrid_inbred_preds$Moisture.Avg)))+
  labs(x = 'Predicted Moisture Content',
       y = 'Actual Moisture Content',
       tag = 'A')+
  stat_cor(aes(label = ..rr.label..), r.digits = 3, show.legend = F, method = 'pearson')+
  theme_classic()+
  theme(text = element_text(size = 12, color = 'black'))

inbred_on_hybrid

ggsave('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Outputs/Inbred_Model_Hybrid_Predictions.png',
       inbred_on_hybrid,
       width = 3.75,
       height = 3.5,
       units = 'in',
       dpi = 300)

```

It appears that while the hybrids are much worse at predicting moisture content (from inbred data) the prediction interval is much tighter.  From what I could tell, the prediction interval for inbreds is about 0.18 whereas hybrids are around 0.075.  The problem here is that the inbreds have a much larger dynamic range than the hybrids, so the hybrids look significantly worse, and they are more confident that they are worse.

# Assessing the Data Similarity
## Spectral Consistancy
Let's look to see if the spectra seem 'overlapped'.  This will be done by creating a PCA with the inbred data and the hybrid data will be predicted into the same coordinate space. 
```{r spectral coordinate space, message = F, warning = F}
inbred_train_pca = prcomp(inbred_train_data[,4:144], scale. = T, center = T)

inbred_train_pcs = inbred_train_pca$x[,1:2]
hybrid_pcs = predict(inbred_train_pca, hybrid_data[str_detect(hybrid_data$Sample_ID, "^YCH"),7:147])[,1:2]
new_hybrids_pcs = predict(inbred_train_pca, hybrid_scans)[,1:2]

# inbred train data vs widiv hybrids
inbred_hybrid_pca_plot = inbred_train_pcs %>%
  as_tibble() %>%
  mutate(Group = 'Inbred') %>%
  bind_rows(new_hybrids_pcs %>%
              as_tibble() %>%
              mutate(Group = 'Hybrid')) %>%
  arrange(Group) %>%
  ggplot(aes(x = PC1, y = PC2, color = Group))+
  geom_point(alpha = 0.5, show.legend = F)+
  stat_ellipse(show.legend = F)+
  scale_color_manual(values = c('darkblue', 'darkred'), breaks = c('Inbred', 'Hybrid'))+
  labs(x = paste0('PC1 (', signif(summary(inbred_train_pca)[[6]][2], 3)*100, '%)'),
     y = paste0('PC2 (', signif(summary(inbred_train_pca)[[6]][5], 3)*100, '%)'),
     tag = 'B')+
  theme_classic()+
  theme(text = element_text(size = 12, color = 'black'))

inbred_hybrid_pca_plot

ggsave('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Outputs/Inbred_Hybrid_PCA_Spectral_Space.png', inbred_hybrid_pca_plot, width = 3.75, height = 2.2, dpi = 300)

# inbred train data vs widiv hybrids
nir_data_22_23 = read_csv('~/Downloads/WiDiv_Inbred_Hybrid_NIR_Data_2022_2023.csv') %>%
  select(Sample_ID, as.character(seq(950,1650,5))) %>%
  mutate(Group = case_when(str_detect(Sample_ID, 'YCH2') ~ 'Hybrid',
                           str_detect(Sample_ID, 'YC2') ~ 'Inbred'),
         .before = 2)

inbreds_used = nir_data_22_23 %>%
  select(1:2) %>%
  left_join(hybrid_genos_xref) %>%
  separate(Genotype, into = c('Egg', 'Pollen'), sep = ' X ') %>%
  filter(Pollen %in% c('B73', 'Mo17')) %>%
  select(Egg) %>%
  unique() %>%
  pull()

inbred_hybrid_22_23_pca_plot = nir_data_22_23 %>%
  select(1:2) %>%
  bind_cols(predict(inbred_train_pca, nir_data_22_23[,3:143])[,1:2]) %>%
  left_join(hybrid_genos_xref) %>%
  separate(Genotype, into = c('Egg', 'Pollen'), sep = ' X ') %>%
  filter(Pollen %in% c('B73', 'Mo17') | Group == 'Inbred') %>%
  filter(Egg %in% inbreds_used) %>%
  ggplot(aes(x = PC1, y = PC2, color = Group))+
  geom_point(alpha = 0.5, show.legend = F)+
  stat_ellipse(show.legend = F)+
  scale_color_manual(values = c('darkblue', 'darkred'), breaks = c('Inbred', 'Hybrid'))+
  labs(x = paste0('PC1 (', signif(summary(inbred_train_pca)[[6]][2], 3)*100, '%)'),
     y = paste0('PC2 (', signif(summary(inbred_train_pca)[[6]][5], 3)*100, '%)'),
     tag = 'C')+
  theme_classic()+
  theme(text = element_text(size = 12, color = 'black'))

inbred_hybrid_22_23_pca_plot

ggsave('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Outputs/Inbred_Hybrid_22_23_PCA_Spectral_Space.png', inbred_hybrid_22_23_pca_plot, width = 3.75, height = 2.2, dpi = 300)

all_inbred_hybrid_pca_plot = inbred_train_pcs %>%
  as_tibble() %>%
  mutate(Group = 'Training Inbreds') %>%
  bind_rows(nir_data_22_23 %>%
              select(1:2) %>%
              bind_cols(predict(inbred_train_pca, 
                                nir_data_22_23[,3:143])[,1:2]) %>%
              left_join(hybrid_genos_xref) %>%
              separate(Genotype, 
                       into = c('Egg', 
                                'Pollen'), 
                       sep = ' X ') %>%
              filter(Pollen %in% c('B73', 
                                   'Mo17') | Group == 'Inbred') %>%
              filter(Egg %in% inbreds_used) %>%
              mutate(Group = case_when(Group == 'Hybrid' ~ 'Hybrids',
                                       Group == 'Inbred' ~ '2022/2023 Inbreds'))) %>%
  sample_frac(1) %>%
  filter(PC2 < 20) %>%
  ggplot(aes(x = PC1, y = PC2, color = Group))+
  geom_point(alpha = 0.5)+
  stat_ellipse(show.legend = F)+
  scale_color_manual(values = c('darkred', 'darkblue', 'aquamarine3'), breaks = c('Training Inbreds', 'Hybrids', '2022/2023 Inbreds'))+
  labs(x = paste0('PC1 (', signif(summary(inbred_train_pca)[[6]][2], 3)*100, '%)'),
     y = paste0('PC2 (', signif(summary(inbred_train_pca)[[6]][5], 3)*100, '%)'),
     tag = 'B')+
  theme_classic()+
  theme(legend.position = 'bottom',
        text = element_text(size = 12, color = 'black'))+
  guides(color = guide_legend(override.aes = list(alpha = 1),
                              nrow = 3))

all_inbred_hybrid_pca_plot

ggsave('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Outputs/All_Inbred_Hybrid_PCA_Spectral_Space.png', all_inbred_hybrid_pca_plot, width = 3.75, height = 4.4, dpi = 300)
```

The hybrid samples appear to all fall within the coordinate space of the inbreds, suggesting they are not more spectrally extreme.

## Compositional Differences

Lets start by looking at the distributions of the inbred and hybrid cook tests.  This will include both density plots for normality and shifts, as well as box plots to look for outliers.
```{r moisture content distributions, message = F, warning = F}
inbred_hybrid_data = inbred_train_data %>%
  select(Sample_ID, Moisture_Uptake) %>%
  mutate(Group = 'Inbred') %>%
  bind_rows(inbred_val_data %>%
              select(Sample_ID, Moisture_Uptake) %>%
              mutate(Group = 'Inbred')) %>%
  bind_rows(hybrid_data %>%
              filter(str_detect(Sample_ID, '^YCH')) %>%
              rename(Moisture_Uptake = Moisture.Avg) %>%
              select(Sample_ID, Moisture_Uptake) %>%
              mutate(Group = 'Hybrid'))

inbred_hybrid_data %>%
  ggplot(aes(x = Moisture_Uptake, fill = Group))+
  geom_density(alpha = 0.5)+
  labs(x = 'Moisture Content')+
  scale_fill_manual(values = c('darkblue', 'darkred'), breaks = c('Inbred', 'Hybrid'))+
  theme_classic()

inbred_hybrid_data %>%
  ggplot(aes(x = Group, y = Moisture_Uptake, fill = Group))+
  geom_boxplot(alpha = 0.5)+
  geom_jitter(aes(color = Group))+
  labs(x = NULL,
       y = 'Moisture Content')+
  scale_color_manual(values = c('darkblue', 'darkred'), breaks = c('Inbred', 'Hybrid'))+
  scale_fill_manual(values = c('darkblue', 'darkred'), breaks = c('Inbred', 'Hybrid'))+
  theme_classic()

t.test(inbred_hybrid_data[inbred_hybrid_data$Group == 'Inbred', 'Moisture_Uptake'],
       inbred_hybrid_data[inbred_hybrid_data$Group == 'Hybrid', 'Moisture_Uptake'])
```

The hybrids seem to fall within the bounds of the inbred training set (better than the inbred validation does by most aspects).  There are a few 'outliers' in each dataset, but most of these samples seem largely fine.  

The moisture distributions between inbreds (train) and hybrids are significantly different (with an effect size of about 0.01). This could be largely driven by the fact that there are nearly 100 degrees of freedom.  Just to be safe, lets consider the differences in composition and spectra.

## Compositional Similarity
```{r compositional consistency, message = F, warning = F}
inbred_comp = inbred_train_data %>%
  select(Sample_ID, Moisture_Uptake) %>% 
  left_join(read_csv('~/Desktop/Grad_School/Research/CHIP-NMC/Data/Burns_et_al_2021_Inbred_Training_Set.csv') %>%
    select(1,2,20:25)) %>%
  rename(Protein = Protein_As_is,
         Starch = Starch_As_is,
         Fat = Fat_As_is,
         Fiber = Fiber_As_is,
         Ash = Ash_As_is)

hybrid_mc_ct = hybrid_data %>%
  select(Sample_ID, Moisture.Avg) %>%
  rename(Moisture_Uptake = Moisture.Avg)

inbred_hybrid_22_23_comp = read_csv('~/Downloads/WiDiv_Inbred_Hybrid_NIR_Data_2022_2023.csv') %>%
  select(Sample_ID, Protein, Starch, Fiber, Fat, Ash, Moisture) %>%
  mutate(Group = case_when(str_detect(Sample_ID, 'YCH2') ~ 'Hybrid',
                           str_detect(Sample_ID, 'YC2') ~ 'Inbred'),
         .before = 2) %>%
  full_join(hybrid_mc_ct) %>%
  mutate(Group = case_when(Group == 'Inbred' ~ '2022/2023 Inbreds',
                           T ~ 'Hybrids'))

inbred_hybrid_comp = inbred_hybrid_22_23_comp %>%
  bind_rows(inbred_comp %>%
              select(-Genotype) %>%
              mutate(Group = 'Training Inbreds')) %>%
  ungroup() %>%
  mutate(Protein = Protein / (1 - (Moisture / 100)),
         Starch = Starch / (1 - (Moisture / 100)),
         Fiber = Fiber / (1 - (Moisture / 100)),
         Fat = Fat / (1 - (Moisture / 100)),
         Ash = Ash / (1 - (Moisture / 100))) %>%
  rename(`Nixtamalization Moisture Content` = Moisture_Uptake)

comp_plot = inbred_hybrid_comp %>%
  select(-Moisture) %>%
  pivot_longer(cols = -c(Sample_ID, Group), names_to = 'Component', values_to = 'Concentration') %>%
  mutate(Component = factor(Component, levels = c('Nixtamalization Moisture Content', 'Protein', 'Starch', 'Fiber', 'Fat', 'Ash'))) %>%
  ggplot(aes(x = Concentration, fill = Group))+
  geom_density(alpha = 0.5, show.legend = F)+
  facet_wrap(~Component, scales = 'free', ncol = 1)+
  labs(x = 'Concentration',
       tag = 'C')+
  scale_fill_manual(values = c('darkblue', 'darkred', 'aquamarine3'), breaks = c('Hybrids', 'Training Inbreds', '2022/2023 Inbreds'))+
  theme_classic()+
  theme(text = element_text(size = 12, color = 'black'))

print(comp_plot)

ggsave('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Outputs/Composition_Distributions.png', comp_plot, width = 3.75, height = 7.9, dpi = 300)

for(trait in c('Nixtamalization Moisture Content', 'Protein', 'Starch', 'Fiber', 'Fat', 'Ash')){
  # Filter data for trait of interest
  data = inbred_hybrid_comp %>%
    filter(!is.na(!!sym(trait)))
  
  # Display how many samples are in the dataset
  print(paste('N =', nrow(data)))
  
  anova_results = aov(lm(data[[trait]] ~ data$Group,
                         na.action = na.exclude))
  
  p_val = summary(anova_results)[[1]][['Pr(>F)']][1]
  
  if(p_val < 0.05){
    print(trait)
    TukeyHSD(anova_results) %>%
      print()
  }
}
```

## Spectral and Moisture Correlation

Now let's look at the correlations between moisture content and waveband absorbance for inbreds and hybrids
```{r absorbance and moisture correlations, message = F, warning = F}
waveband_correlations = tibble(Waveband = NULL,
                               PearsonR = NULL,
                               Group = NULL,
                               lwr = NULL,
                               upr = NULL)

for(wav in as.character(seq(950, 1650, 5))){
  waveband_correlations = waveband_correlations %>%
    bind_rows(tibble(Waveband = as.numeric(wav),
                     Pearson_R = cor.test(inbred_train_data[[wav]], inbred_train_data$Moisture_Uptake)[[4]],
                     Group = 'Inbred',
                     lwr = cor.test(inbred_train_data[[wav]], inbred_train_data$Moisture_Uptake)[[9]][1],
                     upr = cor.test(inbred_train_data[[wav]], inbred_train_data$Moisture_Uptake)[[9]][2])) %>%
    bind_rows(tibble(Waveband = as.numeric(wav),
                     Pearson_R = cor.test(hybrid_data[[wav]], hybrid_data$Moisture.Avg)[[4]],
                     Group = 'Hybrid',
                     lwr = cor.test(hybrid_data[[wav]], hybrid_data$Moisture.Avg)[[9]][1],
                     upr = cor.test(hybrid_data[[wav]], hybrid_data$Moisture.Avg)[[9]][2]))
}



waveband_correlations %>%
  ggplot(aes(x = Waveband, y = Pearson_R^2, ymin = lwr^2, ymax = upr^2, fill = Group, color = Group, group = Group))+
  geom_ribbon(alpha = 0.5, show.legend = F)+
  geom_point()+
  labs(x = 'Waveband',
       y = 'Proportion of Variance Explained (R^2)',
       title = 'Correlation between Moisture Content and Spectral Absorbances')+
  ylim(0,1)+
  scale_color_manual(values = c('darkblue', 'darkred'), breaks = c('Inbred', 'Hybrid'))+
  scale_fill_manual(values = c('darkblue', 'darkred'), breaks = c('Inbred', 'Hybrid'))+
  theme_classic()
```

The correlation between wavebands and moisture content is lower for the hybrids than it was for the inbreds (0.45 compared to 0.57).  The correlations at wavebands between inbreds and hybrids is correlated though, indicating that they follow the same pattern, just don't explain quite as much variation.

## Relationship between wavebands

There is a decent amount of variation amongst the wavebands in terms of how correlated they are with moisture content.  Perhaps we can utilize the more highly correlated samples (if they are different enough from other wavebands). Lets start by looking at how correlated the wavebands are with each other.

```{r interwaveband correlations, message = F, warning = F}
# cor(inbred_train_data %>%
#                 select(-Sample_ID, -Genotype) %>%
#                 as.matrix())[-1,-1] %>%
#   as_tibble() %>%
#   mutate(Waveband_1 = seq(950,1650,5), .before = '950') %>%
#   pivot_longer(cols = -Waveband_1, names_to = 'Waveband_2', values_to = 'Correlation') %>%
#   mutate(Waveband_1 = as.numeric(Waveband_1),
#          Waveband_2 = as.numeric(Waveband_2)) %>%
#   ggplot(aes(x = Waveband_1, y = Waveband_2, fill = Correlation, color = Correlation))+
#   geom_tile(size = 0.3)+
#   scale_x_continuous(limits = c(950,1650), expand = c(0, 0)) +
#   scale_y_continuous(limits = c(950,1650), expand = c(0, 0)) +
#   scale_fill_gradientn(colors = c("white", "blue"), limits = c(0,1))+
#   scale_color_gradientn(colors = c("white", "blue"), limits = c(0,1))+
#   labs(title = 'Correlation between Wavebands in Inbred Training Set',
#        x = 'Waveband 1',
#        y = 'Waveband 2')+
#   theme_classic()
# 
cor(hybrid_scans %>%
                select(-Sample_ID, -Year, -Location, -Source, -Experiment) %>%
                as.matrix()) %>%
  min()
```

Interestingly, the inbreds have a couple areas that are less correlated with each other than others, but are still highly correlated (R >= 0.8).  The Hybrids however, are more highly correlated between the wavebands, with the no correlation below R = 0.9.  This lack of new information from additional wavebands will be problematic and could explain why the inbred does not do a very good job predicting moisture content in hybrids.


# Hybrid Models

## Comparison between training and all hybrid data
### Spectral Profiles
```{r compare training and all hybrid data, message = F, warning = F}
hybrid_pca = prcomp(hybrid_scans[,6:146], scale. = T, center = T)
#summary(hybrid_pca)

hybrid_pcs = hybrid_pca$x[,1:2]

training_spectra_pca = hybrid_pcs %>%
  as_tibble() %>%
  bind_cols(hybrid_scans %>% select(Sample_ID)) %>%
  mutate(Group = case_when(Sample_ID %in% hybrid_data$Sample_ID ~ 'Training',
                           !Sample_ID %in% hybrid_data$Sample_ID ~ 'Remaining')) %>%
  arrange(Group) %>%
  filter(PC2 > -20) %>%
  ggplot(aes(x = PC1, y = PC2, color = Group))+
  geom_point()+
  scale_color_manual(values = c('black', 'gray'), breaks = c('Training', 'Remaining'))+
  theme_classic()+
  labs(x = paste0('PC1 (', signif(summary(hybrid_pca)[[6]][2], 3)*100, '%)'),
     y = paste0('PC2 (', signif(summary(hybrid_pca)[[6]][5], 3)*100, '%)'),
     tag = 'A',
     color = NULL)+
  theme(text = element_text(size = 12, color = 'black'),
        legend.position = 'top',
        legend.margin = margin(t = -0.1, unit = 'in'))

training_spectra_pca

ggsave('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Outputs/Training_Remaining_PCA_Spectral_Space.png', training_spectra_pca, width = 3.75, height = 3.25, dpi = 300)
```

```{r compare training and remaining in each population, message = F, warning = F}
hybrid_pcs_storage = tibble()
for(exp in unique(hybrid_scans$Experiment)){
  if(exp %in% c('Era Hybrids', 'Pilot Trials', 'Commercial Hybrids', 'Unknown')){
    next
  }
  print(exp)
  hybrid_scans_sub = hybrid_scans %>%
    filter(Experiment == exp)
  
  hybrid_pca = prcomp(hybrid_scans_sub[,6:146], scale. = T, center = T)

  hybrid_pcs = hybrid_pca$x[,1:2]
  
  hybrid_pcs_storage = hybrid_pcs_storage %>%
    bind_rows(hybrid_pcs %>%
                as_tibble() %>%
                bind_cols(hybrid_scans_sub %>% select(Sample_ID)) %>%
                mutate(Group = case_when(Sample_ID %in% hybrid_data$Sample_ID ~ 'Training',
                                         !Sample_ID %in% hybrid_data$Sample_ID ~ 'Remaining'),
                       Experiment = exp) %>%
                arrange(Group)) 
}

divided_spectral_rep = hybrid_pcs_storage %>%
  mutate(Experiment = case_when(Experiment == 'Agronomic Trial' ~ 'Commercial Population 1',
                                Experiment == 'Density' ~ 'Commercial Population 2',
                                Experiment == 'Multi-Environment' ~ 'Commercial Population 3',
                                TRUE ~ Experiment)) %>%
  ggplot(aes(x = PC1, y = PC2, color = Group))+
    geom_point()+
    scale_color_manual(values = c('black', 'gray'), breaks = c('Training', 'Remaining'))+
  facet_wrap(~Experiment, scales = 'free', ncol = 2)+
    theme_classic()+
    labs(x = 'PC1',
       y = 'PC2',
       color = NULL)+
    theme(text = element_text(size = 12, color = 'black'),
          legend.position = 'top',
          legend.margin = margin(t = -0.1, unit = 'in'))
  
ggsave('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Outputs/Training_Remaining_PCA_Spectral_Space_Divided.png', divided_spectral_rep, width = 7.5, height = 5, dpi = 300)
```

### Compositional Profiles
```{r compare training and all hybrid data, message = F, warning = F}
hybrid_comp_all = read_csv('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Data/Scans/Hybrid_Maize_Composition_Predictions_Coded.csv') %>%
  filter(Sample_ID %in% toupper(hybrid_scans$Sample_ID)) %>%
  mutate(Group = case_when(Sample_ID %in% hybrid_data$Sample_ID ~ 'Training',
                           !Sample_ID %in% hybrid_data$Sample_ID ~ 'Remaining')) %>%
  ungroup() %>%
  mutate(Protein = Protein / (1 - (Moisture / 100)),
         Starch = Starch / (1 - (Moisture / 100)),
         Fiber = Fiber / (1 - (Moisture / 100)),
         Fat = Fat / (1 - (Moisture / 100)),
         Ash = Ash / (1 - (Moisture / 100))) %>%
  select(-Moisture)

training_samples = hybrid_comp_all %>%
  filter(Group == 'Training')

comp_plot_all = hybrid_comp_all %>%
  pivot_longer(cols = -c(Sample_ID, Group, Genotype),
               names_to = 'Component',
               values_to = 'Concentration') %>%
  mutate(Component = factor(Component, levels = c('Protein', 'Starch', 'Fiber', 'Fat', 'Ash'))) %>%
  ggplot(aes(x = Concentration))+
  geom_density(fill = 'gray')+
  facet_wrap(~Component, scales = 'free', ncol = 1)+
  geom_rug(data = training_samples %>% 
             pivot_longer(cols = -c(Sample_ID, Group, Genotype),
                          names_to = 'Component',
                          values_to = 'Concentration') %>%
              mutate(Component = factor(Component, levels = c('Protein', 'Starch', 'Fiber', 'Fat', 'Ash'))),
           aes(x = Concentration), color = 'black', length = unit(5, units = 'points'))+
  scale_y_continuous(expand = c(0.15,0))+
  labs(x = 'Concentration',
       tag = 'B')+
  theme_classic()+
  theme(legend.position = 'bottom',
        text = element_text(size = 12, color = 'black'))

comp_plot_all

ggsave('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Outputs/Composition_Distributions_All.png', comp_plot_all, width = 3.75, height = 6, dpi = 300)
```


## Hybrid Model Bootstrapping
### Load the Bootstrapped Training Results
```{r bootstrapping boosted and hybrid models, message = F, warning = F}
Path = '~/Desktop/Grad_School/Research/CHIP-NMC/'
# This file cannot be inlcuded in the github repo due to it's size. Please see table S6 for the aggregated results. Contact the author for the full dataset that will allow this section to run as intended.
boot_data = read_csv(paste0(Path, 'Data/ML_Model_Performances_Full_305.csv')) %>% # remove _Full for original analysis
  filter(spectra %in% c('raw', 'snv', 'baseline'))

boot_data %>%
  group_by(model, spectra, hyperparameter, partitioning) %>%
  summarise(n = n(),
            Mean_Spearman_R = mean(spearmanr_test),
            Spearman_R_CV = sd(spearmanr_test) / mean(spearmanr_test),
            Min_Spearman_R = min(spearmanr_test),
            Max_Spearman_R = max(spearmanr_test),
            Mean_RMSE = mean(rmse_test),
            RMSE_CV = sd(rmse_test) / mean(rmse_test),
            Min_RMSE = min(rmse_test),
            Max_RMSE = max(rmse_test)) %>%
  write_csv('~/Desktop/Grad_School/Research/CHIP-NMC/Outputs/Model_Iterations_Table.csv')
```

### Look for the Best Models
```{r look at best models, message = F, warning = F}
boot_summaries = boot_data %>%
  group_by(model, spectra, hyperparameter, partitioning) %>% # removed model_preprocessing
  summarise(n = n(),
            pearsonr_mean = mean(pearsonr_test),
            pearsonr_cv = sd(pearsonr_test) / mean(pearsonr_test),
            spearmanr_mean = mean(spearmanr_test),
            spearmanr_cv = sd(spearmanr_test) / mean(spearmanr_test),
            rmse_mean = mean(rmse_test),
            rmse_cv = sd(rmse_test) / mean(rmse_test))

boot_summaries %>%
  arrange(rmse_mean)

boot_summaries %>%
  arrange(desc(pearsonr_mean))

boot_summaries %>%
  arrange(desc(spearmanr_mean))

ranked_models = boot_data %>%
  ungroup() %>%
  mutate(spearmanr_rank = rank(-spearmanr_test), # we chose to consider spearman R rather than pearson R because they are highly correlated (0.93) and spearman R is more informative for our predictions (due to)
         rmse_rank = rank(rmse_test)) %>%
  group_by(model, spectra, hyperparameter, partitioning) %>% # removed model_preprocessing
  summarise(total_rank = sum(c(spearmanr_rank, rmse_rank))) %>%
  arrange(total_rank)

boot_summaries %>%
  filter(model == 'pls',
         spectra == 'snv',
         hyperparameter == 10,
         partitioning == 'Genotype')

top_models = ranked_models %>%
  group_by(model, partitioning) %>%
  filter(total_rank == min(total_rank)) %>%
  select(c(model, spectra, hyperparameter, partitioning)) # removed model_preprocessing

top_models

boot_summaries %>%
  filter(paste0(model,
                spectra,
                hyperparameter,
                partitioning) %in% paste0(top_models$model,
                                          top_models$spectra,
                                          top_models$hyperparameter,
                                          top_models$partitioning)) %>%
  group_by(partitioning) %>%
  summarise(sd = sd(spearmanr_mean))
```

The PLS model with baseline corrected spectra, scaled data, and an ncomp of 14 appears to perform the best on average.  Many of the PLS models with baseline spectra seem to be performing the best on average.  This instills a lot of confidence when continuing with this model.

```{r determine best combination for each model, message = F, warning = F}
top_model_data = boot_data %>%
  filter(paste0(model,
                spectra,
                hyperparameter,
                #model_preprocessing,
                partitioning) %in% paste0(top_models$model,
                                          top_models$spectra,
                                          top_models$hyperparameter,
                                          #top_models$model_preprocessing,
                                          top_models$partitioning))

top_model_data %>%
  group_by(model, partitioning) %>%
  summarise(hyperparameter = unique(hyperparameter),
            spectra = unique(spectra),
            mean_spearman_r = mean(spearmanr_test),
            cv_spearman_r = sd(spearmanr_test) / mean(spearmanr_test),
            min_spearman_r = min(spearmanr_test),
            max_spearman_r = max(spearmanr_test)) %>%
  write_csv('~/Desktop/Grad_School/Research/CHIP-NMC/Outputs/Top_Model_Performances.csv')

performance_plot = top_model_data %>%
  ggplot(aes(x = factor(model, levels = c('lm', 'rf', 'svmLinear', 'pls')),
             y = spearmanr_test,
             color = model,
             fill = model))+
  geom_violin(alpha = 0.5,
              show.legend = F)+
  geom_jitter(show.legend = F, size = 0.2)+
  scale_color_manual(values = c('gray40', 'gray30', 'gray20', 'black'),
                     breaks = c('lm', 'rf', 'svmLinear', 'pls'))+
  scale_fill_manual(values = c('gray40', 'gray30', 'gray20', 'black'),
                     breaks = c('lm', 'rf', 'svmLinear', 'pls'))+
  stat_summary(color = 'red',
               size = 0.1,
               alpha = 0.5,
               show.legend = F)+
  ylim(-1,1)+
  labs(x = NULL,
       y = 'Spearman R',
       tag = 'C')+
  facet_wrap(~partitioning, nrow = 1)+
  theme_classic()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        text = element_text(size = 12, color = 'black'))

performance_plot

ggsave('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Outputs/Top_Model_Performance.png', 
       performance_plot, width = 3.75, height = 2.75, dpi = 300)
```

The best PLS model narrowly outperformed the best SVML model, which narrowly outperformed the best random forest model.  All of these models significantly outperformed the linear model which was to be expected.

### Factors affecting performance
```{r visualizing factors affecting performance, message = F, warning = F}
# # How does hyperparameter affect performance?
# for(part in unique(boot_summaries$partitioning)){
#   print(boot_summaries %>%
#           pivot_longer(cols = c(pearsonr_mean, spearmanr_mean, rmse_mean),
#                        names_to = 'Metric',
#                        values_to = 'Performance') %>%
#           filter(partitioning == part) %>%
#           ggplot(aes(x = hyperparameter, y = Performance, color = spectra))+
#           geom_point()+
#           geom_smooth(color = 'black', alpha = 0.5, se = F)+
#           labs(title = part)+
#           facet_wrap(Metric~model, scales = 'free')+
#           theme_classic())
# }
# 
# # Which model performed best across all/most data splits?
# top_model_data %>%
#   pivot_longer(cols = c(pearsonr_test, spearmanr_test, rmse_test),
#                names_to = 'Metric',
#                values_to = 'Performance') %>%
#   ggplot(aes(x = seed, y = Performance, color = model, fill = model))+
#   geom_smooth()+
#   facet_wrap(Metric~partitioning, scales = 'free')+
#   theme_classic()
# 
# # Did the models perform better on training or testing data? Hopefully training 
# top_model_data %>%
#   filter(model != 'lm') %>%
#   mutate(row_num = row_number()) %>%
#   pivot_longer(cols = c(pearsonr_test,
#                         pearsonr_train,
#                         rmse_test,
#                         rmse_train,
#                         spearmanr_test,
#                         spearmanr_train),
#                names_to = 'metric_group',
#                values_to = 'Performance') %>%
#   separate(metric_group, c('Metric', 'Group'), '_') %>%
#   ggplot(aes(x = Group, y = Performance, group = row_num, color = model))+
#   geom_line(alpha = 0.1)+
#   geom_smooth(se = F, method = 'lm', aes(group = model))+
#   facet_wrap(Metric ~ partitioning, scales = 'free')+
#   scale_x_discrete(limits = rev)+
#   theme_classic()
```

As can be seen, the PLS model improves at low levels of hyperparameter values for all spectra types, whereas the random forest and SVML models are highly dependent on the type of spectra provided.  We can also see that the PLS and SVML models performed similarly across all seeds (different training/testing splits), and even had a cross over event in early seeds.  RF, while outperforming the linear model did not fare as well as PLS and SVML.

It also appears that the models are performing better on the testing data than on the training cross validations.  This is strange, but not unheard of.  It could mean that the training data is generally more diverse and thus more difficult to predict.  It is also noticeable that the E split data has a slightly more intense regression than the G split data, which is slightly more than the R split data (for the correlation data at least).  I am not entirely sure what would cause this.  Perhaps is has to do with training vs testing size (E is probably the most difficult to split properly for) or it could have to do with data leakage, though I would not expect an increase in performance from partitions that are intended to decrease leakage.

### Determining varition explained by training parameters
```{r quantifying variance explained, message = F, warning = F}
# What is the variation explained due to model training parameters?
boot_summaries_long = boot_summaries %>%
  filter(model != 'lm') %>%
  select(-spearmanr_cv, -pearsonr_cv, rmse_cv) %>%
  pivot_longer(cols = c(pearsonr_mean, spearmanr_mean, rmse_mean), names_to = 'Metric', values_to = 'Performance')

pve = tibble()

for(metric in unique(boot_summaries_long$Metric)){
  print(metric)
  model = lmer(Performance ~ (1 | model) + 
                             (1 | spectra) +
                             (1 | partitioning) +
                             #(1 | model_preprocessing) +
                             (1 | model:spectra) +
                             (1 | model:partitioning) +
                             (1 | model:hyperparameter) + # Hyperparameter is nested within model
                             (1 | spectra:partitioning) +
                             (1 | spectra:hyperparameter) +
                             (1 | partitioning:hyperparameter),
                             #(1 | model:model_preprocessing) +
                             #(1 | spectra:model_preprocessing) +
                             #(1 | partitioning:model_preprocessing)
               data = boot_summaries_long[boot_summaries_long$Metric==metric,])
  
  print(hist(residuals(model)))
  
  pve = pve %>%
    bind_rows(summary(model)$varcor %>%
                as_tibble() %>%
                mutate(Total_SS = sum(vcov),
                       PVE = vcov / Total_SS,
                       Metric = metric))
}

pve %>%
  ggplot(aes(x = factor(grp, levels = c('model',
                                        'spectra',
                                        'partitioning',
                                        #'model_preprocessing',
                                        'model:spectra',
                                        'model:partitioning',
                                        'model:hyperparameter',
                                        'spectra:partitioning',
                                        'spectra:hyperparameter',
                                        'partitioning:hyperparameter',
                                        #'model:model_preprocessing',
                                        #'spectra:model_preprocessing',
                                        #'partitioning:model_preprocessing',
                                        'Residual')),
                        y = PVE))+
  geom_bar(stat = 'identity')+
  labs(x = NULL,
       y = 'Proportion of Variation Explained')+
  coord_flip()+
  scale_x_discrete(limits = rev)+
  facet_wrap(~Metric)+
  theme_classic()
```

It appears that model and spectra explain very little to no variation when the linear model is excluded, which makes some sense since the linear model is consistently an outlier.  The partitioning method explains the most variation which makes sense given that random clearly performed better than genotype which clearly outperformed environment. The model/hyperparameter, model/spectra, and spectra/hyperparameter explain most of the rest of the variation, which make sense given that any model can be bad given the wrong spectra or hyperparmeters, and sometime hyperparameters will perform better on certain spectra. 

## Prediction of Best Hybrid Model
### Select Best Model Information
```{r top model information, message = F, warning = F}
top_model = ranked_models %>%
  ungroup() %>%
  filter(partitioning == 'Genotype') %>% # Random partitioning risks too much data leakage, and genotype partitioning performed the next best across all top models
  filter(total_rank == min(total_rank)) %>%
  select(model, spectra, hyperparameter, partitioning) # removed model_preprocessing

print(top_model)
```

### Train Hybrid Based Model
```{r train hybrid model, message = F, warning = F}
hybrid_snv_data = hybrid_data %>%
  select(-as.character(seq(950,1650,5))) %>%
  bind_cols(as_tibble(detrend(hybrid_data %>%
                                select(as.character(seq(950,1650,5))),
                                wav = as.numeric(seq(950,1650,5)),
                                p = 2)))

hybrid_model = train(Moisture.Avg ~ ., 
                        data = hybrid_snv_data %>%
                          select(-c(Sample_ID, Location, Source, Experiment, Genotype)), 
                        method = "pls", 
                        metric = "Rsquared",
                        #preProcess = c('scale'),
                        tuneGrid = expand.grid(ncomp = 10),
                        trControl = trainControl(method = "cv",
                                                 index = groupKFold(hybrid_snv_data$Genotype, k = 10), 
                                                 savePredictions = T,
                                                 allowParallel = T
                                                 )
                        )
```

### Predict on hybrid scan data
```{r read in hybrid scan data, message = F, warning = F}
hybrid_scans_uncooked = hybrid_scans %>%
  filter(!Sample_ID %in% hybrid_data$Sample_ID) # 3620 - 273 = 3347
```

```{r process data and predict, message = F, warning = F}
hybrid_uncooked_snv_data = hybrid_scans_uncooked %>%
  select(-as.character(seq(950,1650,5))) %>%
  bind_cols(as_tibble(detrend(hybrid_scans_uncooked %>%
                                select(as.character(seq(950,1650,5))),
                                wav = as.numeric(seq(950,1650,5)),
                                p = 2)))

hybrid_scans_uncooked['Moisture_Content_Pred'] = predict(hybrid_model, hybrid_uncooked_snv_data)

hybrid_scans_uncooked %>%
  select(Sample_ID, Moisture_Content_Pred) %>%
  write_csv('~/Desktop/hybrids_predicted_moisture.csv')

hybrid_scans_uncooked %>%
  ggplot(aes(x = Moisture_Content_Pred))+
  geom_histogram()+
  geom_vline(xintercept = min(hybrid_data$Moisture.Avg))+
  geom_vline(xintercept = max(hybrid_data$Moisture.Avg))+
  theme_classic()

mean(hybrid_scans_uncooked$Moisture_Content_Pred)
sd(hybrid_scans_uncooked$Moisture_Content_Pred)

```


```{r learning curve of training data, message = F, warning = F}
# Function for this is found in Hybrid_Model_Training_POC.R
# hybrid_lc = learning_curve(outcome_col = 1,
#                            data = hybrid_baseline_filtered[6:147],
#                            test_partition = 0.2,
#                            partition_by = hybrid_baseline_filtered$Genotype,
#                            reps = 10,
#                            iterations = 4:30,
#                            model = "pls",
#                            metric = "Rsquared",
#                            tuneparams = expand.grid(ncomp = 11))
# 
# hybrid_lc %>%
#   pivot_longer(cols = -c(train_size, rep, p),
#                names_to = 'Group_Metric',
#                values_to = 'Performance') %>%
#   separate(Group_Metric, into = c('Group', 'Metric'), sep = '_') %>%
#   filter(Metric != 'spearmanr') %>%
#   ggplot(aes(x = train_size, y = Performance, color = Group))+
#   geom_point(show.legend = F)+
#   geom_smooth(se = F, show.legend = F)+
#   theme_classic()
```


### Validation of the Hybrid Model
```{r selecting validation samples throughout distribution, message = F, warning = F}
# potential_validation_hybrids = hybrid_scans_uncooked %>%
#   filter(!Sample_ID %in% hybrid_data$Sample_ID) %>%
#   filter(Moisture_Content_Pred < (quantile(Moisture_Content_Pred, 0.75) + (1.5*IQR(Moisture_Content_Pred))) &
#          Moisture_Content_Pred > (quantile(Moisture_Content_Pred, 0.25) - (1.5*IQR(Moisture_Content_Pred))))
# 
# hybrid_even_samples = tibble()
# 
# for(group in unique(potential_validation_hybrids$Experiment)){
#   downsampled_groups = potential_validation_hybrids %>%
#     filter(Experiment == group)
# 
#   if(group == 'Commercial Hybrids' | group == 'Unknown' | group == 'Pilot Trials' | group == 'Era Hybrids'){
#     next
#   }
#   print(group)
#   if(group == 'Agronomic Trial'){
#     even_values = c(quantile(downsampled_groups$Moisture_Content_Pred, 0.333),
#                     quantile(downsampled_groups$Moisture_Content_Pred, 0.667))
#   } else{even_values = seq(min(downsampled_groups$Moisture_Content_Pred),
#                            max(downsampled_groups$Moisture_Content_Pred),
#                            length.out = 15)}
# 
# 
#   for(value in even_values){
#     #print(value) # Debugging
#     hybrid_even_samples = hybrid_even_samples %>%
#       bind_rows(downsampled_groups[abs(downsampled_groups$Moisture_Content_Pred-value) == min(abs(downsampled_groups$Moisture_Content_Pred-value)),] %>%
#                 mutate(closest_value = value,
#                        distance = Moisture_Content_Pred - value))
# 
#     downsampled_groups = downsampled_groups %>% filter(!Sample_ID %in% hybrid_even_samples$Sample_ID)
#   }
# }
# 
# val_samples = hybrid_even_samples %>%
#   left_join(hybrid_genos_xref) %>%
#   distinct(Sample_ID, .keep_all = T) %>%
#   select(Genotype) %>%
#   unique() %>%
#   pull()
# 
# potential_genotypes_for_validation = hybrid_data %>%
#   bind_rows(potential_hybrids_for_cooks %>%
#               left_join(hybrid_genos_xref)) %>%
#   filter(Genotype %in% val_samples) %>%
#   arrange(Experiment) %>%
#   mutate(Moisture = case_when(is.na(Moisture.Avg) ~ Moisture_Content_Pred,
#                               is.na(Moisture_Content_Pred) ~ Moisture.Avg)) %>%
#   select(Sample_ID, Genotype, Experiment, Moisture)
# 
# 
# even_genos_val = tibble()
# 
# for(group in unique(potential_genotypes_for_validation$Experiment)){
#   downsampled_groups = potential_genotypes_for_validation %>%
#     filter(Experiment == group) %>%
#     filter(!Sample_ID %in% c('P1602_Edgar_8', 'YCH22:2437', 'YCH22:1295'))
# 
#   if(group == 'Commercial Hybrids' | group == 'Unknown' | group == 'Pilot Trials' | group == 'Era Hybrids'){
#     next
#   }
#   print(group)
# 
#   even_values = seq(min(downsampled_groups$Moisture),
#                     max(downsampled_groups$Moisture),
#                     length.out = 15)
# 
#   for(value in even_values){
#     #print(value) # Debugging
#     even_genos_val = even_genos_val %>%
#     bind_rows(downsampled_groups[abs(downsampled_groups$Moisture-value) == min(abs(downsampled_groups$Moisture-value)),] %>%
#                 mutate(closest_value = value,
#                        distance = Moisture - value))
# 
#     downsampled_groups = downsampled_groups %>% filter(!Sample_ID %in% even_genos_val$Sample_ID)
#   }
# }
# 
# new_train_data = hybrid_data %>%
#                                 filter(!Genotype %in% even_genos_val$Genotype)

# # Find 2023 samples to add to validation set
# ych23_samples = hybrid_scans_uncooked %>%
#   filter(str_detect(Sample_ID, '^YCH23'))
# 
# # Create an evenly spaced list of length 15 that goes from the minimum to maximum values for the YCH23 samples
# even_values = seq(min(ych23_samples$Moisture_Content_Pred),
#                   max(ych23_samples$Moisture_Content_Pred),
#                   length.out = 15)
#  
# # Find the samples that are closest to these values and extract them from the dataset
# ych23_samples = hybrid_scans_uncooked %>%
#   filter(str_detect(Sample_ID, '^YCH23')) %>%
#   left_join(hybrid_genos_xref) %>%
#   filter(!str_detect(Genotype, 'RIB$'))
# 
# even_genos_val = tibble()
# for(value in even_values){
#     #print(value) # Debugging
#     even_genos_val = even_genos_val %>%
#     bind_rows(ych23_samples[abs(ych23_samples$Moisture_Content_Pred-value) == min(abs(ych23_samples$Moisture_Content_Pred-value)),] %>%
#                 mutate(closest_value = value,
#                        distance = Moisture_Content_Pred - value))
# 
#     ych23_samples = ych23_samples %>% filter(!Sample_ID %in% even_genos_val$Sample_ID)
# }
# 
# even_genos_val %>%
#  filter(!Sample_ID %in% hybrid_data$Sample_ID) %>%
#  select(Sample_ID) %>%
#  write_csv('~/Desktop/Grad_School/Research/CHIP-NMC/Data/Validation_Samples_Final_To_Find_2023.csv')
# 
# #Make labels for cook test packaging
# even_genos_val_labels = even_genos_val %>%
#   filter(!Sample_ID %in% hybrid_data$Sample_ID) %>%
#   select(Sample_ID) %>%
#    mutate(A = NA,
#           B = NA) %>%
#    pivot_longer(cols = c(A, B),
#                 names_to = 'Hotplate_ID') %>%
#    select(-value) %>%
#    sample_frac(1) %>%
#    group_by(Hotplate_ID) %>%
#    mutate(Hotplate_Pos = rep_len(c(1:4), n())) %>%
#    group_by(Hotplate_ID, Hotplate_Pos) %>%
#    mutate(Cook_Day = row_number()) %>%
#    arrange(Cook_Day, Hotplate_ID, Hotplate_Pos)
# 
# even_genos_val_labels %>%
#     write_csv('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Data/Labels/Validation_2023_Samples.csv')
# 
# even_genos_val_labels %>%
#    mutate(Moisture_Y = NA,
#           Moisture_Z = NA,
#           DML_1 = NA,
#           DML_2 = NA) %>%
#    pivot_longer(cols = c(Moisture_Y, Moisture_Z, DML_1, DML_2),
#                 names_to = 'Subsample') %>%
#    select(-value) %>%
#    write_csv('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Data/Labels/Validation_2023_Subsamples.csv')


val_data_snv = hybrid_val_data %>%
  select(-as.character(seq(950,1650,5))) %>%
  bind_cols(as_tibble(detrend(hybrid_val_data %>%
                                select(as.character(seq(950,1650,5))),
                                wav = as.numeric(seq(950,1650,5)),
                                p = 2)))
val_data_snv['Moisture_Content_Pred'] = predict(hybrid_model, val_data_snv)

hybrid_scans_uncooked %>%
  left_join(hybrid_genos_xref) %>%
  ggplot(aes(x = Moisture_Content_Pred))+
  geom_density(fill = 'gray')+
  geom_rug(data = val_data_snv, mapping = aes(x = Moisture_Content_Pred), color = 'red')+
  geom_vline(xintercept = min(hybrid_snv_data %>%
                                select(Moisture.Avg) %>%
                                pull()))+
  geom_vline(xintercept = max(hybrid_snv_data %>%
                                select(Moisture.Avg) %>%
                                pull()))+
  theme_classic()

# mutate(Experiment = case_when())
  
# even_genos_val %>%
#   filter(!Sample_ID %in% hybrid_data$Sample_ID) %>%
#   select(Sample_ID) %>%
#   write_csv('~/Desktop/Grad_School/Research/CHIP-NMC/Data/Validation_Samples_Final_To_Find.csv')

# Make labels for cook test packaging
# even_genos_val_labels = even_genos_val %>%
#   filter(!Sample_ID %in% hybrid_data$Sample_ID) %>%
#   select(Sample_ID) %>%
#   mutate(A = NA,
#          B = NA) %>%
#   pivot_longer(cols = c(A, B),
#                names_to = 'Hotplate_ID') %>%
#   select(-value) %>%
#   sample_frac(1) %>%
#   group_by(Hotplate_ID) %>%
#   mutate(Hotplate_Pos = rep(c(1:4), (n() / 4))) %>%
#   group_by(Hotplate_ID, Hotplate_Pos) %>%
#   mutate(Cook_Day = row_number()) %>%
#   arrange(Cook_Day, Hotplate_ID, Hotplate_Pos)
# 
#  even_genos_val_labels %>%
#    write_csv('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Data/Labels/Validation_Final_Samples.csv')
# 
# even_genos_val_labels %>%
#   mutate(Moisture_Y = NA,
#          Moisture_Z = NA,
#          DML_1 = NA,
#          DML_2 = NA) %>%
#   pivot_longer(cols = c(Moisture_Y, Moisture_Z, DML_1, DML_2),
#                names_to = 'Subsample') %>%
#   select(-value) %>%
#   write_csv('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Data/Labels/Validation_Final_Subsamples.csv')

# Find additional 2023 samples (extreme high and extreme low) to be added to the training set along with the 15 evenly spread samples that were supposed to be validation samples. We are interested in 6 high and 6 low.
ych23_additional_train = hybrid_scans_uncooked %>%
 filter(str_detect(Sample_ID, '^YCH23')) %>%
  filter(!Sample_ID %in% hybrid_val_data$Sample_ID) %>%
 select(Sample_ID, Moisture_Content_Pred) %>%
 arrange(Moisture_Content_Pred) %>%
  left_join(hybrid_genos_xref) %>%
  filter(!str_detect(Genotype, 'RIB$')) %>%
  filter(Sample_ID != 'YCH23:1200',
         Sample_ID != 'YCH23:1564') %>%
 slice(c(1:6, nrow(.):(nrow(.)-5)))
# 
# ych23_additional_train %>%
#  write_csv('~/Desktop/additional_training_samples_2023.csv')
# 
# # Make labels for cook test packaging
# ych23_additional_train_labels = ych23_additional_train %>%
#   filter(!Sample_ID %in% hybrid_data$Sample_ID) %>%
#   select(Sample_ID) %>%
#   mutate(A = NA,
#          B = NA) %>%
#   pivot_longer(cols = c(A, B),
#                names_to = 'Hotplate_ID') %>%
#   select(-value) %>%
#   sample_frac(1) %>%
#   group_by(Hotplate_ID) %>%
#   mutate(Hotplate_Pos = rep(c(1:4), (n() / 4))) %>%
#   group_by(Hotplate_ID, Hotplate_Pos) %>%
#   mutate(Cook_Day = row_number()) %>%
#   arrange(Cook_Day, Hotplate_ID, Hotplate_Pos)
# 
#  ych23_additional_train_labels %>%
#    write_csv('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Data/Labels/ych23_additional_samples_labels.csv')
# 
# ych23_additional_train_labels %>%
#   mutate(Moisture_Y = NA,
#          Moisture_Z = NA,
#          DML_1 = NA,
#          DML_2 = NA) %>%
#   pivot_longer(cols = c(Moisture_Y, Moisture_Z, DML_1, DML_2),
#                names_to = 'Subsample') %>%
#   select(-value) %>%
#   write_csv('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Data/Labels/ych23_additional_samples_Subsamples.csv')
```


```{r verify that validation samples are spread throughout distribution, message = F, warning = F}
facet_labels = c('Agronomic Trial' = 'Commercial Population 1',
                 'Density' = 'Commercial Population 2',
                 'Multi-Environment' = 'Commercial Population 3',
                 'WiDiv Panel Hybrids 2022' = 'WiDiv Panel Hybrids 2022',
                 'WiDiv Panel Hybrids 2023' = 'WiDiv Panel Hybrids 2023',
                 'Overall' = 'Overall')

validation_plot_data = hybrid_scans_uncooked %>%
  left_join(hybrid_genos_xref) %>%
  filter(Experiment != 'Unknown',
         Experiment != 'Commercial Hybrids',
         Experiment != 'Pilot Trials',
         Experiment != 'Era Hybrids') %>%
  mutate(Experiment = case_when(Experiment == 'WiDiv - Hybrids' & str_detect(Sample_ID, '22:') ~ 'WiDiv Panel Hybrids 2022',
                                Experiment == 'WiDiv - Hybrids'  & str_detect(Sample_ID, '23:') ~ 'WiDiv Panel Hybrids 2023',
                                Experiment == 'Agronomic Trial' ~ 'Commercial Population 1',
                                Experiment == 'Density' ~ 'Commercial Population 2',
                                Experiment == 'Multi-Environment' ~ 'Commercial Population 3',
                                TRUE ~ Experiment)) %>%
  bind_rows(hybrid_scans_uncooked %>%
              left_join(hybrid_genos_xref) %>%
              filter(Experiment != 'Unknown',
                     Experiment != 'Commercial Hybrids',
                     Experiment != 'Pilot Trials',
                     Experiment != 'Era Hybrids') %>%
              mutate(Experiment = 'Overall'))

rug_data = val_data_snv %>%
  mutate(Experiment = case_when(Experiment == 'WiDiv - Hybrids' &
                                  str_detect(Sample_ID,'22:') ~ 'WiDiv Panel Hybrids 2022',
                                Experiment == 'WiDiv - Hybrids' &
                                  str_detect(Sample_ID,
                                             '23:') ~ 'WiDiv Panel Hybrids 2023',
                                Experiment == 'Agronomic Trial' ~ 'Commercial Population 1',
                                Experiment == 'Density' ~ 'Commercial Population 2',
                                Experiment == 'Multi-Environment' ~ 'Commercial Population 3',
                                TRUE ~ Experiment)) %>%
             bind_rows(val_data_snv %>% mutate(Experiment = 'Overall'))

validation_distributions = validation_plot_data %>%
  ggplot(aes(x = Moisture_Content_Pred, fill = Experiment, color = Experiment))+
  geom_density(show.legend = F)+
  geom_rug(data = rug_data,
           mapping = aes(x = Moisture_Content_Pred),
           color = 'black',
           length = unit(5, 'points'))+
  xlim(min(hybrid_snv_data %>%
            select(Moisture.Avg) %>%
            pull()),
       max(hybrid_snv_data %>%
            select(Moisture.Avg) %>%
            pull()))+
  scale_y_continuous(expand = c(0.15,0))+
  facet_wrap(~factor(Experiment,
                     levels = c('Commercial Population 1',
                                'WiDiv Panel Hybrids 2022',
                                'Commercial Population 2',
                                'WiDiv Panel Hybrids 2023',
                                'Commercial Population 3',
                                'Overall')),
             nrow = 3)+
  scale_color_manual(breaks = c('Commercial Population 1',
                                'Commercial Population 2',
                                'Commercial Population 3',
                                'WiDiv Panel Hybrids 2022',
                                'WiDiv Panel Hybrids 2023',
                                'Overall'),
                     values = c('darkorchid4',
                                'mediumpurple',
                                'mediumorchid',
                                'dodgerblue4',
                                'dodgerblue',
                                'gray30'))+
  scale_fill_manual(breaks = c('Commercial Population 1',
                                'Commercial Population 2',
                                'Commercial Population 3',
                                'WiDiv Panel Hybrids 2022',
                                'WiDiv Panel Hybrids 2023',
                                'Overall'),
                     values = c('darkorchid4',
                                'mediumpurple',
                                'mediumorchid',
                                'dodgerblue4',
                                'dodgerblue',
                                'gray30'))+
  labs(x = 'Predicted Nixtamalization Moisture Content',
       tag = 'A')+
  theme_classic()+
  theme(text = element_text(size = 11, color = 'black'),
        axis.text.x = element_text(angle = 45, hjust = 1))

print(validation_distributions)

ggsave('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Outputs/validation_sample_selection.png',
       validation_distributions,device = 'png', width = 3.75, height = 3.5, units = 'in')

# For Posters
# val_samp_selection = validation_distributions+
#   theme(text = element_text(size = 30))
# 
# ggsave('~/Desktop/validation_sample_selection.png', val_samp_selection, device = 'png', width = 10, height = 7.5, units = 'in')
```

```{r validation sample cook test data, message = F, warning = F}
# Check out the distribution of values and look for outliers
hybrid_val_data %>%
  ggplot(aes(x = Experiment, y = Moisture.Avg))+
  geom_boxplot()+
  geom_jitter(color = 'gray')+
  theme_classic()
```
It looks like there aren't any outliers in any of the groups!

Now for the moment of truth...
```{r correlating cook test with predictions, message = F, warning = F}
val_data_snv = val_data_snv %>%
  mutate(Experiment = case_when(Experiment == 'WiDiv - Hybrids' & str_detect(Sample_ID, '22:') ~ 'WiDiv Panel Hybrids 2022',
                                Experiment == 'WiDiv - Hybrids'  & str_detect(Sample_ID, '23:') ~ 'WiDiv Panel Hybrids 2023',
                                Experiment == 'Agronomic Trial' ~ 'Commercial Population 1',
                                Experiment == 'Density' ~ 'Commercial Population 2',
                                Experiment == 'Multi-Environment' ~ 'Commercial Population 3',
                                TRUE ~ Experiment))

#cor(val_data_snv$Moisture_Content_Pred, val_data_snv$Moisture.Avg)
cor.test(val_data_snv$Moisture_Content_Pred, val_data_snv$Moisture.Avg, method = 'spearman')

for(exp in unique(val_data_snv$Experiment)){
  exp_data = val_data_snv %>%
    filter(Experiment == exp)
  
  print(exp)
  #print(cor.test(exp_data$Moisture_Content_Pred, exp_data$Moisture.Avg))
  print(cor.test(exp_data$Moisture_Content_Pred, exp_data$Moisture.Avg, method = 'spearman'))
}

correlation_plot = val_data_snv %>%
  mutate(Experiment = case_when(Experiment == 'WiDiv - Hybrids' & str_detect(Sample_ID, '22:') ~ 'WiDiv Panel Hybrids 2022',
                                Experiment == 'WiDiv - Hybrids'  & str_detect(Sample_ID, '23:') ~ 'WiDiv Panel Hybrids 2023',
                                Experiment == 'Agronomic Trial' ~ 'Commercial Population 1',
                                Experiment == 'Density' ~ 'Commercial Population 2',
                                Experiment == 'Multi-Environment' ~ 'Commercial Population 3',
                                TRUE ~ Experiment)) %>%
  ggplot(aes(x = Moisture_Content_Pred, y = Moisture.Avg, color = Experiment))+
  geom_abline(color = 'gray', linetype = 'dashed')+
  geom_point(show.legend = F, alpha = 0.75)+
  geom_smooth(method = 'lm', se = F, show.legend = F)+
  #geom_smooth(method = 'lm', se = F, show.legend = F, color = 'gray30')+
  scale_color_manual(breaks = c('Commercial Population 1',
                                'Commercial Population 2',
                                'Commercial Population 3',
                                'WiDiv Panel Hybrids 2022',
                                'WiDiv Panel Hybrids 2023'),
                     values = c('darkorchid4',
                                'mediumpurple',
                                'mediumorchid',
                                'dodgerblue4',
                                'dodgerblue'))+
  ylim(min(val_data_snv$Moisture.Avg,
           val_data_snv$Moisture_Content_Pred),
       max(val_data_snv$Moisture.Avg,
           val_data_snv$Moisture_Content_Pred))+
  xlim(min(val_data_snv$Moisture.Avg,
           val_data_snv$Moisture_Content_Pred),
       max(val_data_snv$Moisture.Avg,
           val_data_snv$Moisture_Content_Pred))+
  labs(x = 'Predicted Moisture Content',
       y = 'Actual Moisture Content',
       tag = 'B')+
  stat_cor(aes(label = ..rr.label..),
           show.legend = F,
           r.digits = 3,
           method = 'pearson')+
  stat_cor(color = 'black',
           label.y = 0.452,
           aes(label = ..rr.label..),
           show.legend = F,
           r.digits = 3,
           method = 'pearson')+
  theme_classic()+
  theme(text = element_text(size = 12, color = 'black'))

print(correlation_plot)

ggsave('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Outputs/validation_correlation.png',
       correlation_plot, device = 'png', width = 3.75, height = 3.5, units = 'in')
# For Posters
# val_corr = correlation_plot+
#   theme(text = element_text(size = 30),
#         legend.position = 'bottom')
# 
# ggsave('~/Desktop/validation_correlation.png', val_corr, device = 'png', width = 7.5, height = 7.5, units = 'in')
```
The model predicts well!  The agonomic trials are a little steep, and the multi environment isn't perfect near the lower end, but overall the model is predicting well in all categories. Certainly enough to warrant further analyses!

What is the error?
```{r error of model, message = F, warning = F}
RMSE(val_data_snv$Moisture_Content_Pred, val_data_snv$Moisture.Avg)

for(exp in unique(val_data_snv$Experiment)){
  exp_data = val_data_snv %>%
    filter(Experiment == exp)
  
  print(exp)
  print(RMSE(exp_data$Moisture_Content_Pred, exp_data$Moisture.Avg))
}

```


What aspects of the wavebands are important to the model?
```{r permuted importance of wavebands, message = F, warning = F}
baseline_R2 = cor(val_data_snv$Moisture_Content_Pred, val_data_snv$Moisture.Avg)^2

cor_table = tibble()

for(n in 1:100){
  cat('Working on iteration: ', n, '\n')
  for(i in seq(950,1650,5)){
    # Copy data
    data_copy = val_data_snv
    
    # Permute Column
    data_copy[as.character(i)] = sample(val_data_snv[[as.character(i)]])

    # Save correlation
    cor_table = cor_table %>%
      bind_rows(tibble(Waveband = i,
                       Rep = n,
                       R2 = cor(predict(hybrid_model, data_copy), data_copy$Moisture.Avg)^2))
  }
}


importance_plot = cor_table %>%
  group_by(Waveband) %>%
  summarise(R2_Mean = mean(as.numeric(R2))) %>%
  mutate(loss = baseline_R2 - R2_Mean,
        proportion_loss = loss / baseline_R2) %>%
  ggplot(aes(x = Waveband, y = proportion_loss, fill = proportion_loss))+
  geom_bar(stat = "identity", width = 5, show.legend = F)+
  scale_fill_gradient(low = "gray80", high = "black")+
  theme_classic()+
  labs(x = 'Waveband',
       y = expression(paste("Loss of ", R^2)),
       tag = 'A')+
  theme(text = element_text(size = 12, color = 'black'))

print(importance_plot)

ggsave('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Outputs/waveband_importance.png',
       importance_plot, device = 'png', width =7.5, height = 2.5, units = 'in', dpi = 300)

cor_table %>% 
  group_by(Waveband) %>%
  summarise(Mean_R2_Loss = mean(baseline_R2 - mean(as.numeric(R2)))) %>%
  filter(Mean_R2_Loss > 0.2) %>%
  arrange(desc(Waveband))
```

It is very interesting that the important wavebands seem to group together. The peaks seem to fall around 1325, 1490, and 1650.  While NIR is relatively difficult to parse out causative chemical structures due to its combinatorial nature, I found a figure that could shed some light on what these regions could be related to.
https://www.researchgate.net/publication/325626555_Towards_enhancing_sustainable_reuse_of_pre-treated_drill_cuttings_for_construction_purposes_by_near-infrared_analysis_A_review/figures?lo=1

In this paper they show nothing around 1325 (nothing between ~1225 and ~1375), two major groups around 1490 (CONHR (amide) around 1470-1500, and RNH2 (amine) around 1475-1525) suggesting the role of protein, and two possible groups around 1650 (ArCH around 1620-1650, and CH3 around 1620-1710) suggesting aromatic and aliphatic groups.

## Hybrid Model on Inbreds
```{r hybrid model on inbreds, message = F, warning = F}
inbred_snv_val = inbred_val_data %>%
  filter(Sample_ID != 'YC16:1029') %>%
  select(1,3) %>%
  bind_cols(as_tibble(detrend(inbred_val_data[-1,9:149],
                                           wav = as.numeric(colnames(inbred_val_data[-1,9:149])),
                                           p = 2)))

cor(inbred_snv_val$Moisture_Uptake, predict(hybrid_model, inbred_snv_val))

plot(predict(hybrid_model, inbred_snv_val),
     inbred_snv_val$Moisture_Uptake, 
     xlab = 'Predicted Moisture Content',
     ylab = 'Actual Moisture Content',
     xlim = c(0.35, 0.55),
     ylim = c(0.35, 0.55))
```
The hybrid model is halfway decent at predicting inbreds (0.632)!

## Correlation of Composition and Nixtamalization Moisture Content
```{r relationship between yield and moisture content, message = F, warning = F}
widiv_plot_xref = read_csv(paste0(Path, 'Data/XRefs/2022_2023_field_planning_widiv_xref.csv')) %>%
  filter(Source != 'Andy') %>%
  select(Plot, Block, Rep) %>%
  mutate(Plot = toupper(Plot))

mc_comp_data = hybrid_scans_uncooked %>% 
  select(Sample_ID, Experiment, Moisture_Content_Pred) %>%
  left_join(hybrid_genos_xref) %>%
  filter(!str_detect(Genotype, 'X LH244$'),
         str_detect(Sample_ID, '^YCH')) %>%
  mutate(Year = paste0('20', str_extract(Sample_ID, '[0-9][0-9]'))) %>%
  left_join(widiv_plot_xref, by = c('Sample_ID' = 'Plot')) %>%
  left_join(hybrid_comp_all %>%
              select(Sample_ID, Protein, Starch, Fat, Ash, Fiber),
            by = 'Sample_ID') %>%
  filter(!is.na(Moisture_Content_Pred),
         !is.na(Protein)) %>%
  mutate(Genotype = toupper(Genotype)) %>%
  separate(Genotype, into = c('Egg_Parent', 'Pollen_Parent'), sep = ' X ') %>%
  filter(!is.na(Pollen_Parent)) %>% # Remove commercial lines
  mutate(Year = as.factor(Year),
         Block = as.factor(Block),
         Rep = as.factor(Rep))

# Determine BLUPs for moisture content, composition traits, and yield
traits = c('Moisture_Content_Pred', 'Protein', 'Starch',
           'Fiber', 'Fat', 'Ash')
blup_data = tibble()
for(trait in traits){
  model = paste0('lmer(', trait, ' ~ (1|Egg_Parent) +
                                     Pollen_Parent +
                                     (1|Year/Rep/Block) + 
                                     (1|Egg_Parent:Year),
                          data = mc_comp_data)')
  
  blup_data = blup_data %>% 
    bind_rows(ranef(eval(parse(text = model)))$Egg_Parent %>%
                as_tibble(rownames = 'Egg_Parent') %>%
                rename(BLUP = `(Intercept)`) %>%
                mutate(Trait = paste(trait, 'BLUP', sep = '_')))
}

blup_data %>%
  pivot_wider(id_cols = Egg_Parent,
              values_from = BLUP,
              names_from = Trait) %>%
  select(-Egg_Parent) %>%
  cor()

correlation_plot = blup_data %>%
  pivot_wider(id_cols = Egg_Parent,
              values_from = BLUP,
              names_from = Trait) %>%
  pivot_longer(cols = -c(Egg_Parent, Moisture_Content_Pred_BLUP),
               names_to = 'Trait',
               values_to = 'BLUP') %>%
  mutate(Egg_Parent = str_remove_all(Egg_Parent, ' '),
         Egg_Parent = str_remove_all(Egg_Parent, '-')) %>%
  mutate(Trait = str_remove(Trait, '_BLUP'),
         Trait = str_remove(Trait, 'Corrected_'),
         Trait = paste(Trait, 'BLUP', sep = ' '),
         Trait = factor(Trait, levels = c('Yield BLUP', 'Protein BLUP', 'Starch BLUP', 'Fat BLUP', 'Fiber BLUP', 'Ash BLUP'))) %>%
  ggplot(aes(x = BLUP, y = Moisture_Content_Pred_BLUP))+
  geom_point()+
  geom_smooth(color = 'gray30', se = F, method = 'lm')+
  stat_cor(aes(label = after_stat(r.label)),
           method = "pearson",
           show.legend = FALSE,
           r.digits = 3,
           label.y = 0.0132) +
  stat_cor(aes(label = after_stat(p.label)),
           method = "pearson",
           show.legend = FALSE,
           r.digits = 3,
           label.y = 0.0105)+
  facet_wrap(~Trait, scales = 'free_x', nrow = 1)+
  labs(x = NULL,
       y = 'Predicted Nixtamalization\nMoisture Content BLUP',
       tag = 'B')+
  ylim(min(blup_data$BLUP[blup_data$Trait == 'Moisture_Content_Pred_BLUP']),
       max(blup_data$BLUP[blup_data$Trait == 'Moisture_Content_Pred_BLUP'])+0.005)+
  theme_classic()+
  theme(text = element_text(size = 12, color = 'black'),
        plot.margin = margin(0.3,0.3,0.3,0.3, 'cm'))

correlation_plot

ggsave('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Outputs/correlation_plot.png',
       correlation_plot, device = 'png', width = 7.5, height = 2.5, units = 'in')
```
I would assume this trend would be positive, though I am not surprised at how weak the correlation is.  In theory, increasing yield should increase starch and decrease protein. This decrease in protein should lead to higher moisture contents.  There is a chance for a Simpson's paradox to be happening here with the way fields are blocked (by flowering date, and thus don't have much overlap), but it would be helpful to look at the protein correlation with both yield and moisture content.

```{r blup correlations for met hybrids, message = F, warning = F}
comm_met_comps = hybrid_comp_all %>%
  mutate(Sample_ID = toupper(Sample_ID)) %>%
  left_join(hybrid_scans_uncooked %>%
              mutate(Sample_ID = toupper(Sample_ID)) %>%
              select(Sample_ID, 
                     Experiment,
                     Location,
                     Moisture_Content_Pred)) %>%
  filter(Experiment %in% c('Agronomic Trial',
                           'Density',
                           'Multi-Environment'),
         Group == 'Remaining') %>%
  mutate(Location = case_when(Location == 'StJoseph, IL' ~ 'St. Joseph, IL',
                              T ~ Location))

traits = c('Moisture_Content_Pred', 'Protein', 'Starch',
           'Fiber', 'Fat', 'Ash')

for(exp in unique(comm_met_comps$Experiment)){
  # Display iteration
  print(exp)
  
  # Create a storage tibble
  blup_data = tibble()
  
  # Agronomic trial is set up differently than the others
  if(exp == "Agronomic Trial"){
    # Read in xref file for planting density and combine it to the subset of data
    comm_met_comps_sub = comm_met_comps %>%
      filter(Experiment == exp) %>% 
      left_join(read_csv('~/Desktop/Grad_School/Research/CHIP-NMC/Data/XRefs/PA_Hybrids_XRef_Coded.csv') %>%
                  mutate(Sample_ID = paste0('PA_', Barcode)) %>%
                  select(Sample_ID, Rep, Population))
    
    # Determine BLUPs for moisture content and composition traits
    for(trait in traits){
      # Create the mixed linear model
      model = paste0('lmer(', trait, ' ~ (1|Genotype) +
                                       (1|Location) +
                                       (1|Population) +
                                       (1|Genotype:Location)+
                                       (1|Rep),
                            data = comm_met_comps_sub)')
      
      # Extract and save the blups
      blup_data = blup_data %>% 
        bind_rows(ranef(eval(parse(text = model)))$Genotype %>%
                    as_tibble(rownames = 'Genotype') %>%
                    rename(BLUP = `(Intercept)`) %>%
                    mutate(Trait = trait,
                           Experiment = exp))
    }
  } else {
    if(exp == "Density"){
      # Read in xref file for planting density and combine it to the subset of data
      comm_met_comps_sub = comm_met_comps %>%
        filter(Experiment == exp) %>%
        separate(Sample_ID,
                 into = c('Genotype', 'Location', 'Density'),
                 sep = '_') 
      
      # Determine BLUPs for moisture content and composition traits
      for(trait in traits){
        # Create the mixed linear model
        model = paste0('lmer(', trait, ' ~ (1|Genotype) +
                                         (1|Location) +
                                         (1|Density),
                              data = comm_met_comps_sub)')
        
        # Extract and save the blups
        blup_data = blup_data %>% 
          bind_rows(ranef(eval(parse(text = model)))$Genotype %>%
                      as_tibble(rownames = 'Genotype') %>%
                      rename(BLUP = `(Intercept)`) %>%
                      mutate(Trait = trait,
                             Experiment = exp))
      }
    }
      else {
      # Subset the data
      comm_met_comps_sub = comm_met_comps %>%
        filter(Experiment == exp)
      
      # Determine BLUPs for moisture content and composition traits
      for(trait in traits){
        # Create the mixed linear model
        model = paste0('lmer(', trait, ' ~ (1|Genotype) +
                                         (1|Location),
                              data = comm_met_comps_sub)')
        
        # Extract and save the BLUPs
        blup_data = blup_data %>% 
          bind_rows(ranef(eval(parse(text = model)))$Genotype %>%
                      as_tibble(rownames = 'Genotype') %>%
                      rename(BLUP = `(Intercept)`) %>%
                      mutate(Trait = trait,
                             Experiment = exp))
      }
    }
  }
  # Plot out the correlations
  met_blup_correlations = blup_data %>%
    pivot_wider(id_cols = c(Genotype, Experiment),
                values_from = BLUP,
                names_from = Trait) %>%
    pivot_longer(cols = -c(Genotype, Experiment, Moisture_Content_Pred),
                 names_to = 'Trait',
                 values_to = 'BLUP') %>%
    mutate(Trait = paste0(Trait, ' BLUP')) %>%
    ggplot(aes(x = BLUP, y = Moisture_Content_Pred))+
    geom_point(color = 'gray50')+
    geom_smooth(se = F, method = 'lm', color = 'gray50')+
    stat_cor()+
    facet_wrap(~factor(Trait, levels = c('Protein BLUP', 'Starch BLUP', 'Fat BLUP', 'Fiber BLUP', 'Ash BLUP')), scales = 'free', ncol = 1)+
    labs(y = if(exp == "Agronomic Trial") 'Predicted Nixtamalization Moisture Content BLUP',
         x = NULL,
         tag = c("Multi-Environment" = 'C',
                 "Density" = 'B',
                 "Agronomic Trial" = 'A')[[exp]])+
    theme_classic()+
    theme(text = element_text(size = 12, color = 'black'))
  
  # Save the plots
  ggsave(paste0('~/Desktop/Grad_School/Research/CHIP-NMC/Outputs/',
                exp,
                'blup_correlation_plot.png'),
         met_blup_correlations,
         device = 'png',
         width = 2.5,
         height = 8.5,
         units = 'in')
}
```

# Application Performance
The CHIP-NMC application was timed by hand on a 2019 13in macbook pro. Lets read in the data and show the performance
```{r read in app speed data, message = F, warning = F}
app_speed = read_csv('~/Downloads/HNMC_Model - Table S7.csv', skip = 1)
```

Now lets plot the data to show how long the app takes to run.
```{r displaying application speed results, message = F, warning = F}
app_speed_plot = app_speed %>%
  mutate(Total_Time = Upload_Time + Prediction_Time) %>%
  pivot_longer(cols = c(Upload_Time, Prediction_Time, Total_Time),
               names_to = 'Process',
               values_to = 'Time') %>%
  mutate(Process = str_remove(Process, '_Time')) %>%
  group_by(N_Lines, Model_Option, Process) %>%
  summarise(Time = mean(Time)) %>%
  ggplot(aes(x = N_Lines, y = Time, color = Model_Option, shape = Process, linetype = Process))+
  geom_smooth(show.legend = F, method = 'lm', se = F, linewidth = 0.5)+
  geom_point(fun = mean_cl_boot, size = 2)+
  labs(x = 'Number of Lines',
       y = 'Time (s)',
       tag = 'D',
       color = 'Model',
       shape = 'Process')+
  scale_color_manual(values = c('darkred', 'darkblue'), breaks = c('Inbred', 'Hybrid'))+
  scale_linetype_manual(values = c('solid', 'dashed', 'dotted'), breaks = c('Total', 'Prediction', 'Upload'))+
  scale_shape_manual(values = c('circle', 'square', 'triangle'), breaks = c('Total', 'Prediction', 'Upload'))+
  theme_classic()+
  theme(text = element_text(size = 12, color = 'black'),
        legend.position = 'bottom',
        legend.box = 'vertical',
        legend.spacing.y = unit(0.0, 'cm'),
        legend.margin = margin(0,0,0,0, 'cm'))

app_speed_plot

ggsave('/Users/michael/Desktop/Grad_School/Research/CHIP-NMC/Outputs/app_speed_plot.png',
       app_speed_plot, device = 'png', width = 3.75, height = 3, units = 'in', dpi = 300)

```



